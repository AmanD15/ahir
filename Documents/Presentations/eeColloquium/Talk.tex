\documentclass{beamer}
\usepackage{epsfig}
\title{Mapping algorithms to hardware\\ the AHIR story}
\author{Madhav P. Desai \\ Department of Electrical Engineering\\
  Indian Institute of Technology -- Bombay, Powai, Mumbai -- 400076, INDIA}
\date{January 21, 2015}
\begin{document}

\maketitle

\frame[containsverbatim]{\frametitle{The premise}


\begin{itemize}
\item Hardware capacity has scaled, but design capability has remained stagnant.
\begin{itemize}
\item evidence: anecdotal, most chips today are cut-and-paste/repetitive.
\end{itemize}
\item Hardware capability/efficiency is not fully exploited in implementing complex algorithms.
\end{itemize}

}

\frame[containsverbatim]{\frametitle{Our work}

\begin{itemize}
\item Make the path to ASIC/FPGA simpler for algorithm developers.
\item Develop (and use) a compiler flow for mapping algorithms to hardware.
\item Currently, we have a fully functional tool-chain which takes a C program to VHDL.  
	A multi-threaded C program (with statically defined threads) can
	be easily mapped to a hardware pipeline.
\item We are now working on optimizations (will talk more about that later)
and {\bf applications}.
\end{itemize}

}


\frame[containsverbatim]{\frametitle{Acknowledgements}

Sameer Sahasrabudhe worked out many of the basic ideas as part of
his Ph.D. thesis  and also contributed most of the initial code for the first version of the tools. 
Thanks to Kavi Arya for many interesting discussions and inputs.  Maybe some day we will have
a front end for functional programming languages.
Kartik Lakhotia contributed to the FPGA implementation effort.
Thanks to Teemu Rinta-Aho and G. Caffarena for providing valuable user feedback.
}

\frame[containsverbatim]{\frametitle{How good is the compiler flow?}
We have some experimental data (from 2010)\footnote{S. Sahasrabuddhe, S. Subramanian,
K. Ghosh, K. Arya, M.P. Desai, ``A C-to-RTL flow as an energy efficient alternative
to embedded processors in digital systems'', EUROMICRO 2010, Lille France.} :
	\begin{itemize}
	\item comparison in terms of area, delay and {\bf energy}.
	\item for a set of programs, use standard commercial synthesis tools to obtain
		 an ASIC starting from the RTL generated by the C-to-RTL flow.
	\item compare with processor implementations of the same set of programs.
	\end{itemize}
}


\frame[containsverbatim]{\frametitle{How applicable is it?}
We have some data from a practical use-scenario (from 2012)\footnote{T. Rinta-Aho, M. Karlstedt,
M. P. Desai, ``The Click2Netfpga toolchain'', USENIX ATC 2012, Boston USA.}:
	\begin{itemize}
	\item The Click2Netfpga toolchain (joint work with T. Rinta-Aho, M. Karlstedt
		at Ericsson research) converts a C++ program (generated by the Click
		modular router) to VHDL.
	\item Verified on FPGA, performance up to 50\% of hand-coded Verilog.
	\end{itemize}
}


\frame[containsverbatim]{\frametitle{The starting point: the algorithm}
We view the algorithm as a program:
\begin{itemize}
\item which describes the behaviour of a collection of static threads (no spawning on the fly).
\item the threads interact using shared memory and FIFOs.
\item can be expressed in C.
\end{itemize}
}

\frame[containsverbatim]{\frametitle{The end point: a logic circuit}

\begin{figure}
\begin{centering}
\centerline{\psfig{figure=AhirSystem.eps,width=2.5in,height=2.0in}}
\end{centering}
\end{figure}

\begin{itemize}
\item A collection of modules (a module is
similar to a function in a C program).  The modules communicate
with the environment, with each other (through calls, and through
FIFO pipes), and with memory subsystems. 
\end{itemize}

}

\frame[containsverbatim]{\frametitle{An AHIR module}

An AHIR module description is of the form: 

\begin{displaymath}
{\bf CP} \ \times \ {\bf DP} \ \times \ {\bf S}
\end{displaymath}

where ${\bf CP}$ represents control flow, ${\bf DP}$ represents 
data flow, and {\bf S} represents storage.
}

\frame[containsverbatim]{\frametitle{The control path ${\bf CP}$}

\begin{itemize}
\item The control path is modeled by a petri-net.  Each transition 
is associated with a symbol, which can either be an input symbol
or an output symbol.
\item When a transition labeled by an input symbol is enabled, 
it fires when the input symbol is received.
\item When a transition labeled by an output symbol is enabled,
it fires eventually and emits the output symbol.
\item The petri-net has a special structure, which guarantees that
{\bf CP} is live and safe.
\end{itemize}
}

\frame[containsverbatim]{\frametitle{Type-2 petri-nets} 
Type-2 petri-nets\footnote{Introduced in Sameer Sahasrabudhe's Ph.D. thesis} 
are live and safe petri-nets constructed using a
set of simple rules.  The simplest type-2 petri-net has the form
shown in the figure.
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=Type2Base.eps,width=2.5in,height=2.0in}}
\end{centering}
\end{figure}
}


\frame[containsverbatim]{\frametitle{Production rules} 
Replace a transition by a transition-place-transition (any region produced
from a transition is called a t-region):
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=Type2T1.eps,width=2.5in,height=1.5in}}
\end{centering}
\end{figure}
}

\frame[containsverbatim]{\frametitle{Production rules} 
Replace a transition by an acyclic graph constructed using
transitions and p-regions: the acyclic graph must have a
single source and a single sink.
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=Type2T2.eps,width=2.5in,height=2.0in}}
\end{centering}
\end{figure}
}

\frame[containsverbatim]{\frametitle{Production rules} 
Replace a place by a possibly cyclic graph consisting of
places and t-regions.
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=Type2P1.eps,width=2.3in,height=2.0in}}
\end{centering}
\end{figure}
}

\frame[containsverbatim]{\frametitle{Production rules: pipelines} 
Using token-preserving regions, we can construct a well-behaved
pipeline.
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=PipelineTPR.eps,width=4.5in,height=2.0in}}
\end{centering}
\end{figure}

Note: this can be generalized to DAG.
}


\frame[containsverbatim]{\frametitle{Liveness and Safety} 

\begin{itemize}
\item   Assume that an enabled input transition eventually fires.  Then the type-2
petri-net is live and safe.
\item The type-2 petri-net is also powerful enough to describe the control
flow in imperative languages such as C/C++ as well as in synchronous
languages such as Esterel.
\end{itemize}

}


\frame[containsverbatim]{\frametitle{The data path ${\bf DP}$}

\begin{itemize}
\item A directed graph of operators.
\item Each operator has a set of request symbols and a set of acknowledge symbols.
The operator responds to the arrival of request symbols by eventually generating
appropriate acknowledge symbols.
\item Operator library: all the standard arithmetic and logical operators, as
well as a multiplexor and load/store operators.
\end{itemize}
}

\frame[containsverbatim]{\frametitle{CP-DP interactions}
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=CPxDPxInteraction.eps,width=4.0in,height=3.0in}}
\end{centering}
\end{figure}
}

\frame[containsverbatim]{\frametitle{The storage subsystem ${\bf S}$}
\begin{itemize}
\item The storage subsystem connects to the load/store operators in the datapath,
and is required to eventually service the load/store requests.
\item Declared variables in the source program are grouped
into storage spaces.  
\item The storage spaces are determined by
static reference analysis (the system can have
several distinct memory subsystems).
\item The memory subsystems impose a strong consistency model: all accesses are time-stamped,
and accesses to the same memory location are finished in first-come-first-served
order.
\end{itemize}
}

\frame[containsverbatim]{\frametitle{An example: the dot-product} 
Consider the program fragment:
\begin{verbatim}
float A[1024], B[1024];
float dotP = 0.0;
for(I=0; I < 1024; I++) {
   dotP += A[I]*B[I];
}
\end{verbatim}
}

\frame[containsverbatim]{\frametitle{Dot-product virtual circuit} 
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=dotP.eps,width=4.0in,height=3.0in}}
\end{centering}
\end{figure}
}


\frame[containsverbatim]{\frametitle{Optimizations} 
\begin{itemize}
\item Local dependency analysis: extract local parallelism.
\item Operator sharing: e.g. non-concurrent operations can be mapped to the same
physical operator.
\item Memory decomposition: different data structures can be mapped to different
memories.
\item Loop pipelining: the hardware can keep multiple iterations of a loop in
progress so that throughput is improved.
\end{itemize}
}

\frame[containsverbatim]{\frametitle{Memory decomposition: static aliasing analysis}
\begin{verbatim}
int A, B, C, D; // storage objects.
int foo()
{
   int ret_val = 0;
   int* p1 = &A;
   ret_val += *p1;
   int *p2 = &B;
   ret_val += *p2;
   int *p3 = &C;
   ret_val += *p3;
   p3 = &D;
   ret_val += *p3;
   return(ret_val);
}
\end{verbatim}
}


\frame[containsverbatim]{\frametitle{Memory decomposition: grouping}

\begin{itemize}
\item The memory spaces are $\{A\}$, $\{ B\}$, $\{ C, D \}$.
\item $C$ and $D$ are grouped together because pointer $p3$ can
point to either $C$ or $D$.
\end{itemize}

}

\frame[containsverbatim]{\frametitle{Loop pipelining}
\begin{verbatim}
void Daemon()
{
  while(1)
  {
    float a = read_float32("a_pipe");
    float b = read_float32("b_pipe");
    float c = read_float32("c_pipe");
    write_float32("d_pipe", (a+b)*c);
  }
}
\end{verbatim}
}


\frame[containsverbatim]{\frametitle{Loop Pipelining: dependencies across iterations}
\begin{itemize}
\item Loop pipelining involves executing multiple iterations of a
loop at the same time.
\item While doing this, all dependencies must be taken care of.
\begin{itemize}
\item Operation order.
\item Data dependency.
\item Memory accesses.
\item Pipe accesses.
\end{itemize}
\end{itemize}
Currently, we are a bit conservative.  High performance compiler
community has made substantial progress here.
}

\frame[containsverbatim]{\frametitle{Our C-to-VHDL flow} 
\begin{itemize}
\item The starting point is a program written in C
\begin{itemize}
\item restrictions: no cycles in call graph, and no {\bf function} pointers.
\end{itemize}
\item Use the CLANG front end to convert C program into LLVM byte code (CDFG).
\item Map the CDFG to an Ahir assembly program (using the
{\bf Aa} language, in which parallelism can be expressed in a native
way). 
\item Map the {\bf Aa} description to a virtual circuit consisting
of interacting AHIR modules.
\begin{itemize}
\item identify disjoint memory spaces.
\item dependency analysis to maximize parallelism in straight-line code.
\end{itemize}
\item Map the virtual circuit to VHDL.
\begin{itemize}
\item identify arbiter-less resource sharing opportunities to reduce hardware
cost.
\item instantiate the system: modules with their control and data-paths, the
inter-module link layer to handle calls, the memory subsystem.
\end{itemize}
\end{itemize}
}

\frame[containsverbatim]{\frametitle{Our C-to-VHDL flow} 
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=AhirFlow.eps,width=3.0in,height=3.0in}}
\end{centering}
\end{figure}

}
\frame[containsverbatim]{\frametitle{Mapping to VHDL} 
\begin{itemize}
\item A synchronous, single clock, positive edge-triggered paradigm 
is used.
\item Transitions are coded as pulses which are sampled high by one
clock edge. 
\item Only join transitions need flip-flops for their implementation. 
Other elements are purely combinational in nature, and in many cases,
can be optimized away.
\item The datapath is mapped to an equivalent VHDL netlist constructed
using a library of operators.  When a set of operations shares
a single operator, input multiplexors and output demultiplexors are introduced.
\item The memory subsystem is implemented using multiple banks, and can
offer multiple ports (performance-cost tradeoff).
\end{itemize}
}


\frame[containsverbatim]{\frametitle{Experimental Evaluation 1}
\begin{itemize}
\item Select a range of programs
\begin{itemize}
\item A5 (stream cipher), AES encryption, Red-black Trees (data-structure),
      Linpack (LU factorization), Fast-Fourier Transform (FFT).
\end{itemize}
\item Using the C-to-VHDL flow, map each program to RTL.  The run-time for
mapping is neglible in all cases (less than a minute).
\item Use standard synthesis tools (Synopsys Design Compiler, Cadence SOC encounter)
to implement ASIC from RTL (we use the 180nm TSMC CMOS process, with OSU standard
cell libraries).  Extract area, delay and energy numbers for the implemented ASIC.
\begin{itemize}
\item Operators are not pipelined or optimized in any fashion.
\end{itemize}
\item Run each program on a  processor based platform (we use the Intel Atom N270 as
a reference).  Extract area, delay, energy numbers using the processor data sheet.
\item Compare the ASIC numbers with the processor numbers.
\end{itemize}
} 


\frame[containsverbatim]{\frametitle{Comparison of normalized (to 45nm) C-to-VHDL circuits with 45nm processor}
\begin{table}[htb]
  \centering
  \caption{Area/Delay/Power/Energy RATIOS (processor values relative to the scaled C-to-RTL circuit values)}
  \label{table:Ratios}
  \renewcommand\arraystretch{1.2}
  \setlength{\tabcolsep}{1ex}
  \begin{tabular}{c|c|c|c|c|c}
    \hline
    & Area & Freq & Delay & Power & Energy \\
    \hline
    \hline
    A5/1 & 275.8 & 5.6 & 1.7 & 68.5 & 116.6  \\
    \hline
    AES & 61.5 & 5.6 & 0.34 & 14.8 & 4.9 \\
    \hline
    FFT & 78.4 & 9.6 & 0.57 & 52.6 & 30.3  \\
    \hline
    LPK & 14.8 & 9.6 & 0.84 & 18.3 & 15.3  \\
    \hline
    RBT & 22.2 & 9.6 & 0.15 & 32.7 & 4.7 \\
    \hline
  \end{tabular}
\end{table}
}


\frame[containsverbatim]{\frametitle{Analysis}

\begin{itemize}
\item The C-to-RTL circuits are between 4.7X and 116X more energy efficient than the processor.
\item The processor delays are lower than those of the C-to-RTL circuit in most
cases (except for A5) but the difference is less than one order of magnitude in
all cases.
\begin{itemize}
\item pipelining of operators and retiming of the C-to-RTL circuits should reduce
this gap.
\end{itemize}
\end{itemize}
For single-threaded applications, the C-to-RTL circuits have much better 
energy efficiency than the processor, but have lower performance than the processor.  
\vspace{0.1in}

{\bf Update: }  Loop optimizations seem to be very useful for improving single
thread performance (we will talk about this later).

}

\frame[containsverbatim]{\frametitle{Experimental Evaluation 2: Click2Netfpga}

This work is a joint effort with Teemu Rinta Aho and 
Mika Karlstedt at Ericsson Research, and will be presented
at the USENIX ATC 2012 (Boston).

\begin{itemize}
\item Click is a modular framework for describing networking
devices (e.g. routers, classifiers etc.).  A Click description
is converted to C++ code, which can then be compiled and executed.
\item The Click2Netfpga tool-chain takes Click-generated C++ code
and produces VHDL which can be mapped to the Stanford NetFPGA card
and validated in real-time.
\begin{itemize}
\item The Click2llvm front-end generates LLVM
modules (which form a pipeline) from
the C++ code.
\item The AHIR tool flow maps the LLVM modules to a hardware pipeline.
\end{itemize}
\item A router generated in this manner gives up to 50\% of the
performance of a reference (hand-coded Verilog) design.
\end{itemize}

{\bf Update:} Loop optimizations should reduce the gap between hand-designed
and compiler generated hardware (will talk about this later).
}

\frame[containsverbatim]{\frametitle{Trends}

\begin{itemize}
\item On purely sequential code, the hardware that is generated
consumes substantially less energy than a processor running the
same code.  Performance of single-threaded hardware needs to
improve.
\item For processing pipelines inferred from application
specific C++ code, the performance is upto 50\% of hand-coded
Verilog.   The performance gap needs attention, but 50\% of
hand-coded is ``not bad''.
\end{itemize}

Offers a viable option to the system designer (in addition
to the use of embedded processors and custom hardware).
}

\frame[containsverbatim]{\frametitle{Optimizations: loop-pipelining}

Clearly, there is scope for improvement. 
The most critical problem in improving single-thread performance
is the inner loop.  
\begin{verbatim}
float A[1024], B[1024];
float dotP = 0.0;
for(I=0; I < 1024; I++) {
   dotP += A[I]*B[I];
}
\end{verbatim}
Execute multiple-iterations of a loop whenever possible.  
}

\frame[containsverbatim]{\frametitle{Dynamic loop-pipelining}

In an AHIR system, loop-pipelining can be managed if 
the control-path can maintain dependencies across loops:
\begin{itemize}
\item $F_k \rightarrow F_{k+1}$ for all operations $F$, for all $k$.
\item If $G$ depends on $F$, then $F_k \rightarrow G_k \rightarrow F_{k+1}$.
\item If $P, Q$ are memory operations with an explicit dependency (WAR, RAW, WAW),
then $P_k \rightarrow Q_k \rightarrow P_{k+1} \rightarrow Q_{k+1}$.
\end{itemize}
}

\frame[containsverbatim]{\frametitle{Modified control-path for dynamic loop-pipelining}
\begin{figure}
\begin{centering}
\centerline{\psfig{figure=pipelinedCP.eps,width=3.0in,height=3.0in}}
\end{centering}
\end{figure}
}

\frame[containsverbatim]{\frametitle{Impact of dynamic loop-pipelining on single-threads}
We looked at some simple, but important examples:
\begin{itemize}
\item Dot-product.
\item FFT.
\item Matrix-multiply.
\end{itemize}

In each case, single-threaded performance improvements were measured.
Number of FP adders and multipliers used = 1 of each.
}

\frame[containsverbatim]{\frametitle{Impact of loop-optimizations on the 64-point dot-product}

For the 64-point dot-product (time/area numbers taken from FPGA logic
synthesis targeting a Xilinx Virtex-6):
\begin{verbatim}

             plain     pipelined   unrolled   unrolled
                                              and 
                                              pipelined

Cycles       4071       1874        1894        582
LUTs         4288       5195        4809       7344
FFs          3799       4345        4378       5911
Freq.(MHz)   199.7      199.7       199.7      199.7
\end{verbatim}

Best case FLOPS/cycle = 127/582 = 0.22.
}

\frame[containsverbatim]{\frametitle{Impact of loop-optimizations on the 64-point FFT}

For a single stage of the 64-point FFT (32 butterflies, 300 FP ops).
\begin{verbatim}

            plain     pipelined   unrolled   unrolled
                                             and 
                                             pipelined

Cycles       4151       2885       3110       1064
LUTs        12155      23139      16032       37831
FFs         11955      18632      15299       28698
Freq.(MHz)  186.9      164.1      186.9       164.1
\end{verbatim}

Best case FP-ops/cycle = 300/1064 = 0.3.
}

\frame[containsverbatim]{\frametitle{Impact of loop-optimizations on the 16x16 matrix-multiply}

Here, some aggressive loop-unrolling was used.
\begin{verbatim}

             plain    pipelined  unrolled   unrolled
                                            and 
                                            pipelined
Cycles       161K       77K         13K        7810
LUTs         6323      9408       14891       31744
FFs          6974      8818       12041       21060
Freq.(MHz)   199.7     199.7        186       164.1
\end{verbatim}

Best case FLOPS/cycle = 7936/7810 =1.01.
}

\frame[containsverbatim]{\frametitle{Observations}

\begin{itemize}
\item Excellent performance improvement with loop-pipelining and unrolling.
\item Single-threaded hardware performance is pretty OK.
\begin{itemize}
\item BUT: resource utilization levels need to be improved (anything above
50\% is reasonable).
\item Main cause is latency in non-parallel code (Amdahl's law).  This effect
can be reduced by reducing latency in the logic (in progress).
\item As the problem size is increased, utilization levels tend to increase.
\end{itemize}
\item In practice, we will need to use multiple threads to exploit advantages
of hardware relative to the processor.
\end{itemize}
}


\frame[containsverbatim]{\frametitle{Future directions for our research}
\begin{itemize}
\item Applications: signal processing (image/multi-media), cryptology, 
CFD, Databases etc.
\item Optimizations:  latency reductions, alternative DP structures.
\item Algorithm-to-ASIC, potential asynchronous implementations.
\item Front-end stuff:
\begin{itemize}
\item Other front-ends (going beyond C), OpenMP, OpenCL support.
\item More aggressive compiler optimizations.
\end{itemize}
\end{itemize}
}

\frame[containsverbatim]{\frametitle{Conclusion}

The AHIR flow is open-source.  If you wish to try
it out, please get in touch with me: madhav@ee.iitb.ac.in
or search on github (standard disclaimers apply).

Thank you!
}

\end{document}
